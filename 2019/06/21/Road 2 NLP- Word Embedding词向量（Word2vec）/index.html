<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.4.0 -->
    <script>window.materialVersion = "1.4.0"</script>

    <!-- Title -->
    
    <title>
        
            Road 2 NLP- Word Embedding词向量（Word2vec） | 
        
        Eajack&#39;s Blog
    </title>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">
    
    
    
    
    
    
    
        <link rel="dns-prefetch" href="https://busuanzi.ibruce.info">
    
    
    
    

    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="Eajack Lau">
    <meta name="description" itemprop="description" content="Someday I will be a giant...">
    <meta name="keywords" content=",NLP,Word2vec">

    <!-- Site Verification -->
    
    

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/favicon.jpg">
    <link rel="icon" sizes="192x192" href="/img/favicon.jpg">
    <link rel="apple-touch-icon" href="/img/favicon.jpg">

    <!--iOS -->
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Eajack&#39;s Blog">

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="https://eajack.github.io">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Road 2 NLP- Word Embedding词向量（Word2vec） | Eajack&#39;s Blog">
    <meta property="og:image" content="/img/favicon.jpg">
    <meta property="og:description" content="Someday I will be a giant...">
    <meta property="og:article:tag" content="NLP"> <meta property="og:article:tag" content="Word2vec"> 

    
        <meta property="article:published_time" content="6月 21, 2019">
        <meta property="article:modified_time" content="7月 02, 2019">
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:title" content="Road 2 NLP- Word Embedding词向量（Word2vec） | Eajack&#39;s Blog">
    <meta name="twitter:description" content="Someday I will be a giant...">
    <meta name="twitter:image" content="/img/favicon.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://eajack.github.io">

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html">
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Eajack&#39;s Blog",
        "logo": "/img/favicon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Eajack Lau",
        "image": {
            "@type": "ImageObject",
            "url": "/img/favicon.jpg"
        },
        "description": "Someday I will be a giant..."
    },
    "headline": "Road 2 NLP- Word Embedding词向量（Word2vec）",
    "url": "https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html",
    "datePublished": "6月 21, 2019",
    "dateModified": "7月 02, 2019",
    "description": "Someday I will be a giant...",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://eajack.github.io"
    }
}
</script>


    

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(key){try{localStorage.removeItem(key)}catch(e){}};lsloader.setLS=function(key,val){try{localStorage.setItem(key,val)}catch(e){}};lsloader.getLS=function(key){var val="";try{val=localStorage.getItem(key)}catch(e){val=""}return val};versionString="/*"+materialVersion+"*/";lsloader.clean=function(){try{var keys=[];for(var i=0;i<localStorage.length;i++){keys.push(localStorage.key(i))}keys.forEach(function(key){var data=lsloader.getLS(key);if(data&&data.indexOf(versionString)===-1){lsloader.removeLS(key)}})}catch(e){}};lsloader.clean();lsloader.load=function(jsname,jspath,cssonload){cssonload=cssonload||function(){};var code;code=this.getLS(jsname);if(code&&code.indexOf(versionString)===-1){this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload);return}if(code){var versionNumber=code.split(versionString)[0];if(versionNumber!=jspath){console.log("reload:"+jspath);this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload);return}code=code.split(versionString)[1];if(/\.js?.+$/.test(versionNumber)){this.jsRunSequence.push({name:jsname,code:code});this.runjs(jspath,jsname,code)}else{document.getElementById(jsname).appendChild(document.createTextNode(code));cssonload()}}else{this.requestResource(jsname,jspath,cssonload)}};lsloader.requestResource=function(name,path,cssonload){var that=this;if(/\.js?.+$/.test(path)){this.iojs(path,name,function(path,name,code){that.setLS(name,path+versionString+code);that.runjs(path,name,code)})}else if(/\.css?.+$/.test(path)){this.iocss(path,name,function(code){document.getElementById(name).appendChild(document.createTextNode(code));that.setLS(name,path+versionString+code)},cssonload)}};lsloader.iojs=function(path,jsname,callback){var that=this;that.jsRunSequence.push({name:jsname,code:""});try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(path,jsname,xhr.response);return}}that.jsfallback(path,jsname)}};xhr.send(null)}catch(e){that.jsfallback(path,jsname)}};lsloader.iocss=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.iofonts=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.runjs=function(path,name,code){if(!!name&&!!code){for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code=code}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var script=document.createElement("script");script.appendChild(document.createTextNode(this.jsRunSequence[0].code));script.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(script);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var that=this;var script=document.createElement("script");script.src=this.jsRunSequence[0].path;script.type="text/javascript";this.jsRunSequence[0].status="loading";script.onload=function(){that.jsRunSequence.shift();if(that.jsRunSequence.length>0){that.runjs()}};document.body.appendChild(script)}};lsloader.tagLoad=function(path,name){this.jsRunSequence.push({name:name,code:"",path:path,status:"failed"});this.runjs()};lsloader.jsfallback=function(path,name){if(!!this.jsnamemap[name]){return}else{this.jsnamemap[name]=name}for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code="";this.jsRunSequence[k].status="failed";this.jsRunSequence[k].path=path}}this.runjs()};lsloader.cssfallback=function(path,name,cssonload){if(!!this.cssnamemap[name]){return}else{this.cssnamemap[name]=1}var link=document.createElement("link");link.type="text/css";link.href=path;link.rel="stylesheet";link.onload=link.onerror=cssonload;var root=document.getElementsByTagName("script")[0];root.parentNode.insertBefore(link,root)};lsloader.runInlineScript=function(scriptId,codeId){var code=document.getElementById(codeId).innerText;this.jsRunSequence.push({name:scriptId,code:code});this.runjs()};lsloader.loadCombo=function(jslist){var updateList="";var requestingModules={};for(var k in jslist){var LS=this.getLS(jslist[k].name);if(!!LS){var version=LS.split(versionString)[0];var code=LS.split(versionString)[1]}else{var version=""}if(version==jslist[k].path){this.jsRunSequence.push({name:jslist[k].name,code:code,path:jslist[k].path})}else{this.jsRunSequence.push({name:jslist[k].name,code:null,path:jslist[k].path,status:"comboloading"});requestingModules[jslist[k].name]=true;updateList+=(updateList==""?"":";")+jslist[k].path}}var that=this;if(!!updateList){var xhr=new XMLHttpRequest;xhr.open("get",combo+updateList,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){that.runCombo(xhr.response,requestingModules);return}}else{for(var i in that.jsRunSequence){if(requestingModules[that.jsRunSequence[i].name]){that.jsRunSequence[i].status="failed"}}that.runjs()}}};xhr.send(null)}this.runjs()};lsloader.runCombo=function(comboCode,requestingModules){comboCode=comboCode.split("/*combojs*/");comboCode.shift();for(var k in this.jsRunSequence){if(!!requestingModules[this.jsRunSequence[k].name]&&!!comboCode[0]){this.jsRunSequence[k].status="comboJS";this.jsRunSequence[k].code=comboCode[0];this.setLS(this.jsRunSequence[k].name,this.jsRunSequence[k].path+versionString+comboCode[0]);comboCode.shift()}}this.runjs()}})();</script>

    <!-- Import CSS & jQuery -->
    
        <style id="css/material.min.css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("css/material.min.css","/css/material.min.css?fJTiM/K1J3dWIruo3pxtAw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";})</script>
        <style id="css/style.min.css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("css/style.min.css","/css/style.min.css?oCSEO3ST+aEypEwttTDI9g==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";})</script>
        
        
            <style>
    
    
    
    
    
    
    
    .footer-sns-github {
        background-image: url(data:image/svg+xml;base64,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);
    }
    
    
    
    .footer-sns-zhihu {
        background-image: url(data:image/svg+xml;base64,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);
    }
    
    
    
</style>

        
        <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-image: url(/img/bg.jpg);
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


        <script>lsloader.load("js/jquery.min.js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==")</script>
    
    
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Analytics -->
    

    <!-- Custom Head -->
    
</head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->

    <!-- Left aligned menu below button -->
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    
    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#1-参考资料"><span class="post-toc-number">1.</span> <span class="post-toc-text">1. 参考资料</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#2-Word2vec原理（《word2vec-Parameter-Learning-Explained》）"><span class="post-toc-number">2.</span> <span class="post-toc-text">2. Word2vec原理（《word2vec Parameter Learning Explained》）</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-1-One-Word-Context（CBOW-amp-Skip-Gram一致的最简单情形）"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">2.1. One-Word Context（CBOW &amp; Skip-Gram一致的最简单情形）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-2-CBOW（Continuous-Bag-of-Word-Model）"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">2.2 CBOW（Continuous Bag-of-Word Model）</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-2-1-Multi-Word-Context"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">2.2.1 Multi-Word Context</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-3-Skip-Gram"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">2.3 Skip-Gram</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-4-Hierarchical-Softmax"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">2.4 Hierarchical Softmax</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-5-Negative-Sampling"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">2.5 Negative Sampling</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#3-总结"><span class="post-toc-number">3.</span> <span class="post-toc-text">3. 总结</span></a></li></ol>
        <!--
        <li class="mdl-menu__item">
            Some Action
        </li>
        -->
    </ul>
    





<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        
            <!-- Random Thumbnail -->
            <div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
            <script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 19 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script>

        
    
            <p class="article-headline-p">
                Road 2 NLP- Word Embedding词向量（Word2vec）
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/img/avatar.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Eajack Lau</strong>
        <span>6月 21, 2019</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/NLP/">NLP</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/Word2vec/">Word2vec</a>
    </ul>
    

    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    
        
            <!-- Busuanzi Views -->
            <a class="post_share-link" href="#">
                <li class="mdl-menu__item">
                    <span id="busuanzi_container_page_pv">
                        <span id="busuanzi_value_page_pv"></span>&nbsp;浏览量
                    </span>
                </li>
            </a>
        
    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=Road 2 NLP- Word Embedding词向量（Word2vec）&url=https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html&pic=&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=Road 2 NLP- Word Embedding词向量（Word2vec）&url=https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html&via=Eajack Lau" target="_blank">
            <li class="mdl-menu__item">
                分享到 Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    
        <a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Eajack&#39;s Blog&title=Road 2 NLP- Word Embedding词向量（Word2vec）&summary=Someday I will be a giant...&pics=https://eajack.github.io/img/favicon.jpg&url=https://eajack.github.io/2019/06/21/Road 2 NLP- Word Embedding词向量（Word2vec）/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 QQ
            </li>
        </a>
    

    <!-- Share Telegram -->
    
</ul>

</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <h1 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1. 参考资料"></a>1. 参考资料</h1><blockquote>
<ul>
<li>Word2vec 开山之作1：《Distributed Representations of Sentences and Documents》，作者Mikolov</li>
<li>Word2vec 开山之作2：《Efficient estimation of word representations in vector space》，作者Mikolov</li>
<li>Word2vec论文讲解：《word2vec Parameter Learning Explained》,作者Xin Rong</li>
<li>知乎专栏文：<a href="https://zhuanlan.zhihu.com/p/26306795" target="_blank" rel="noopener">[NLP] 秒懂词向量Word2vec的本质</a></li>
<li>博客文章：<a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a></li>
</ul>
</blockquote>
<p>以下为<a href="https://zhuanlan.zhihu.com/p/26306795" target="_blank" rel="noopener">[NLP] 秒懂词向量Word2vec的本质</a> 的推荐资料分析：</p>
<pre><code>1. Mikolov 两篇原论文：
『Distributed Representations of Sentences and Documents』
      贡献：在前人基础上提出更精简的语言模型（language model）框架并用于生成词向量，这个框架就是 Word2vec
『Efficient estimation of word representations in vector space』
      贡献：专门讲训练 Word2vec 中的两个trick：hierarchical softmax 和 negative sampling
优点：Word2vec 开山之作，两篇论文均值得一读
缺点：只见树木，不见森林和树叶，读完不得要义。
      这里『森林』指 word2vec 模型的理论基础——即 以神经网络形式表示的语言模型
      『树叶』指具体的神经网络形式、理论推导、hierarchical softmax 的实现细节等等

2. 北漂浪子的博客：『深度学习word2vec 笔记之基础篇』
优点：非常系统，结合源码剖析，语言平实易懂
缺点：太啰嗦，有点抓不住精髓

3. Yoav Goldberg 的论文：『word2vec Explained- Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method』
优点：对 negative-sampling 的公式推导非常完备
缺点：不够全面，而且都是公式，没有图示，略显干枯

4. Xin Rong 的论文：『word2vec Parameter Learning Explained』：
！重点推荐！
理论完备由浅入深非常好懂，且直击要害，既有 high-level 的 intuition 的解释，也有细节的推导过程
一定要看这篇paper！一定要看这篇paper！一定要看这篇paper！

5. 来斯惟的博士论文『基于神经网络的词和文档语义向量表示方法研究』以及他的博客（网名：licstar）
可以作为更深入全面的扩展阅读，这里不仅仅有 word2vec，而是把词嵌入的所有主流方法通通梳理了一遍

6. 几位大牛在知乎的回答：『word2vec 相比之前的 Word Embedding 方法好在什么地方？』
刘知远、邱锡鹏、李韶华等知名学者从不同角度发表对 Word2vec 的看法，非常值得一看

7. Sebastian 的博客：『On word embeddings - Part 2: Approximating the Softmax』
详细讲解了 softmax 的近似方法，Word2vec 的 hierarchical softmax 只是其中一种
</code></pre><p><strong>对比上述所有资料，重点看《word2vec Parameter Learning Explained》，并期望基于此文完全弄懂Word2vec原理。</strong></p>
<h1 id="2-Word2vec原理（《word2vec-Parameter-Learning-Explained》）"><a href="#2-Word2vec原理（《word2vec-Parameter-Learning-Explained》）" class="headerlink" title="2. Word2vec原理（《word2vec Parameter Learning Explained》）"></a>2. Word2vec原理（《word2vec Parameter Learning Explained》）</h1><p><strong>Word2vec = CBOW + Skip-Gram（Hierarchical Softmax &amp; Negative Sampling）</strong></p>
<p>其中，</p>
<ul>
<li>CBOW：上下文词语 预测 中心词</li>
<li>Skip-Gram：中心词 预测 上下文词语</li>
</ul>
<h2 id="2-1-One-Word-Context（CBOW-amp-Skip-Gram一致的最简单情形）"><a href="#2-1-One-Word-Context（CBOW-amp-Skip-Gram一致的最简单情形）" class="headerlink" title="2.1. One-Word Context（CBOW &amp; Skip-Gram一致的最简单情形）"></a>2.1. One-Word Context（CBOW &amp; Skip-Gram一致的最简单情形）</h2><ul>
<li>问题描述：最简单情形，<strong>input =&gt; 当前词，output =&gt; 下一个词，即输入当前词预测下一个词</strong></li>
<li>模型框架</li>
</ul>
<p>为方便解说，这里不直接引用原论文图，自己重新Visio画。</p>
<p><img src="https://raw.githubusercontent.com/Eajack/NLP-Papers/master/Word%20Embedding%E8%AF%8D%E5%90%91%E9%87%8F/Word2vec/%E5%9B%BE1.png" alt="图1- One-Word-Context"></p>
<p>(1). Input layer：输入：$X_{V×1} = OneHot(wordNow)$（模型外部输入input1）, 初始化随机矩阵$W_{V×N}$（<strong>PS：$W_{V×N}$第w行的行向量 $V_w$,称作输入向量(input vector)，Size为：1×N，N为词向量维度，V&gt;&gt;N</strong>）。输出：$h_{N×1}=W_{V×N}^{T}X_{V×1}$。</p>
<p>(2). Hidden layer：输入：Input层输出$h_{N×1}$，初始化随机矩阵 $W^{‘}_{V×N}$（<strong>PS：$W^{‘}_{V×N}$的第w列的列向量 , $V^{‘}_w$称作输出向量(output vector)，Size为：N×1</strong>）。输出：$u_{V×1}=W^{‘T}_{N×V}h_{N×1}$。</p>
<p>(3). Output layer：输入：Hidden层输出$u$。输出：$y_j = \frac{exp(u_j)}{\sum_{a=1}^{V}exp(u_a)}$（预测输出Y_predict）。实际输出（模型外部输入input2）$YReal=OneHot(wordNext)$。Y_predict &amp; Y_real构造loss function更新权值$W$、$W^{‘}$。</p>
<p>输入向量矩阵$W$、输出向量矩阵$W^{‘}$，均可作为词语的词向量表示。<strong>但是Word2vec采用输入向量矩阵$W$</strong>。原因：输出向量矩阵$W^{‘}$更新代价大，以下为《word2vec Parameter Learning Explained》原文</p>
<pre><code>1. 英文原文：
Learning the input vectors is cheap; but learning the output vectors is very expensive. 

From the update equations (22)and (33), we can and that, in order to update v_w , for each training instance, we have to iterate through every word w_j in the vocabulary, compute their net input u_j , probability prediction y_j (or y_{cj} for skip-gram), their prediction error e_j (or EI_j for skip-gram), and finally use their prediction error to update their output vector v^{&#39;}_{j}.

Doing such computations for all words for every training instance is very expensive,
making it impractical to scale up to large vocabularies or large training corpora. 

To solve this problem, an intuition is to limit the number of output vectors that must be updated per training instance. One elegant approach to achieving this is hierarchical softmax; another approach is through sampling, which will be discussed in the next section.

2. 中文翻译（Google）：
学习输入向量很便宜; 但学习输出向量非常昂贵。

从更新方程（22）和（33），我们可以和那个为了更新v_w，对于每个训练实例，我们必须遍历词汇表中的每个单词w_j，计算它们的净输入u_j，概率预测y_j（ 或者y_ {cj}用于skip-gram），它们的预测误差e_j（或者用于skip-gram的EI_j），并且最后使用它们的预测误差来更新它们的输出向量v^{&#39;}_{j}。

对每个训练实例的所有单词进行此类计算非常昂贵，
使扩展到大型词汇表或大型培训语料库变得不切实际。

为了解决这个问题，直觉是限制每个训练实例必须更新的输出向量的数量。 实现这一目标的一个优雅方法是分层softmax; 另一种方法是通过抽样，这将在下一节中讨论。
</code></pre><p><strong>这段文字有2个结论：（1）训练输入向量更容易；（2）Hierarchical Softmax &amp; Negative Sampling 方法都是用于更新输出向量的。</strong></p>
<ul>
<li>模型本质</li>
</ul>
<p>通过上面对3层分析，Word2vec模型本质：<strong>训练更新权值矩阵W，即输入向量矩阵，作为词向量表。因为矩阵W尺寸为V×N，则每一行的行向量对应着该位置的词的Word2vec词向量</strong></p>
<ul>
<li>模型例子</li>
</ul>
<p>词库为：“我”、“喜欢”、“苹果”，对应的One-Hot词向量分别为[1,0,0]、[0,1,0]、[0,0,1]。输入到One-Word-Context CBOW模型，取词向量维度N=2（一般V&gt;&gt;N，此处V=3，作为例子取N=2）经过训练得到W矩阵如下：</p>
<script type="math/tex; mode=display">
W = \begin{bmatrix}0.2 & 0.4\\\\0.6 &0.7\\\\0.8 &0.1\end{bmatrix}</script><p>尺寸为V x N，即3 x 2。因此，“我”的Word2vec词向量为[0.2, 0.4]，“喜欢”的Word2vec词向量为[0.6, 0.7]，“苹果的”Word2vec词向量为[0.8, 0.1]。</p>
<ul>
<li>loss function</li>
</ul>
<p>Output层的预测输出：$y_j = \frac{exp(u_j)}{\sum_{a=1}^{V}exp(u_a)}$</p>
<p>联合额外公式：$h_{N×1}=W_{V×N}^{T}X_{V×1}=v_{wI}^{T}$、 <script type="math/tex">u_j=V_w^{'T}h_{N×1}</script> PS：$u_j$为标量，$V_w^{‘T}$尺寸为1×N。</p>
<p>推导出：</p>
<script type="math/tex; mode=display">
y_j = \frac{exp(V_{w_j}^{'T}v_{wI}^{T})}{\sum_{a=1}^{V}{exp(V_{w_a}^{'T}v_{wI}^{T}})}</script><p>令loss function为最大似然函数：</p>
<script type="math/tex; mode=display">
E=log(y_j)=u_j - log(\sum_{a=1}^{V}exp(u_a))</script><ul>
<li>模型训练：参数更新（BP/SGD算法）</li>
</ul>
<p>PS：此处涉及矩阵求导。。也不是很懂，尽可能去理解。部分公式可能编辑有问题，能理解原意即可。</p>
<p>(1). $W^{‘}$更新：$u→W^{‘}$(output→hidden)</p>
<p>$u$：$\frac{\partial E}{\partial u_j}=y_j - t_j := e_j$（y$_j$为实际输出；$t_j=1(j=j^{real})$，$j$为预测输出y位置，$j^{real}$后者则为实际输出；$e_j为$预测error）</p>
<p>$W^{‘}$：$\frac{\partial E}{\partial w_{ij}}=\frac{\partial E}{\partial u_j} - \frac{\partial u_j}{\partial w_{ij}} := e_j * h_i$</p>
<p><strong>更新公式</strong>：</p>
<script type="math/tex; mode=display">
w_{ij}^{(new)} = w_{ij}^{(old)}  - η * e_j * h_i</script><script type="math/tex; mode=display">
V_{wj}^{'(new)} = V_{wj}^{'(old)}  - η * e_j * h</script><p>$V_{wj}$为$W^{‘}$矩阵的第$j$列的列向量，即输出向量。</p>
<p>(2). $W$更新：$h→W$(hidden→input)</p>
<p>$h：\frac{\partial E}{\partial h_i}=\sum_{j=1}^{V}{\frac{\partial E}{\partial u_j}\frac{\partial u_j}{\partial h_i}} =\sum_{j=1}^{V}{e_j * w^{‘}_{ij}}:= Z_i$</p>
<p>$W：\frac{\partial E}{\partial w_{ki}}=\frac{\partial E}{\partial h_i}\frac{\partial h_i}{\partial w_{ki}}=Z_i*X_k$</p>
<p>PS：$\frac{\partial E}{\partial W}=X_{V×1}叉乘Z$，叉乘定义：$a 叉乘 b = |a||b|sin(a,b)$。由于$X$仅有唯一位置非0，则$\frac{\partial E}{\partial W}$仅有唯一的一行非零向量，其值为$Z^T$</p>
<p><strong>更新公式</strong>：</p>
<script type="math/tex; mode=display">
V^{(new)}_{wI}=V^{(old)}_{wI}-η*Z^{T}</script><p>$V_{wI}$为$W$矩阵的第$i$行的行向量，即输入向量。</p>
<p>至此One-Word-Context所有原理结束，接下来的Multi-Word CBOW &amp; Skip-Gram模型原理和这个差别不大，仅在此基础上修改部分公式。</p>
<h2 id="2-2-CBOW（Continuous-Bag-of-Word-Model）"><a href="#2-2-CBOW（Continuous-Bag-of-Word-Model）" class="headerlink" title="2.2 CBOW（Continuous Bag-of-Word Model）"></a>2.2 CBOW（Continuous Bag-of-Word Model）</h2><h3 id="2-2-1-Multi-Word-Context"><a href="#2-2-1-Multi-Word-Context" class="headerlink" title="2.2.1 Multi-Word Context"></a>2.2.1 Multi-Word Context</h3><p>Multi-Word的意思是说，多个上下文词语 =&gt; 中心词（当前词）。<strong>CBOW，即为One-Word-Context的Input layer扩展</strong>。此处直接借用文献图</p>
<p><img src="https://raw.githubusercontent.com/Eajack/NLP-Papers/master/Word%20Embedding%E8%AF%8D%E5%90%91%E9%87%8F/Word2vec/%E5%9B%BE2.PNG" alt="图2- CBOW"></p>
<ul>
<li>和One-Word-Context的唯一区别：$h=\frac{1}{C}W^{T}(x_{1}+x_{2}+···+x_{C})=\frac{1}{C}(V_{w1}+V_{w2}+···+V_{wC})^{T}$，<strong>即取上下文总共C个词语的One-Hot编码，上下文词数分别为$\frac{2}{C}$，求平均所有Input layer输入</strong>。</li>
</ul>
<h2 id="2-3-Skip-Gram"><a href="#2-3-Skip-Gram" class="headerlink" title="2.3 Skip-Gram"></a>2.3 Skip-Gram</h2><p>同CBOW理，<strong>Skip-Gram，即为One-Word-Context的Output layer扩展</strong>。</p>
<p><img src="https://raw.githubusercontent.com/Eajack/NLP-Papers/master/Word%20Embedding%E8%AF%8D%E5%90%91%E9%87%8F/Word2vec/%E5%9B%BE3.PNG" alt="图3- Skip-Gram"></p>
<ul>
<li>和One-Word-Context的唯一区别：loss function<script type="math/tex; mode=display">
\begin{aligned} E &=-\log p\left(w_{O, 1}, w_{O, 2}, \cdots, w_{O, C} | w_{I}\right) \\ &=-\log \prod_{c=1}^{C} \frac{\exp \left(u_{c, j_{c}}^{*}\right)}{\sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right)} \\ &=-\sum_{c=1}^{C} u_{j_{c}^{*}}+C \cdot \log \sum_{j^{\prime}=1}^{V} \exp \left(u_{j^{\prime}}\right) \end{aligned}</script></li>
</ul>
<h2 id="2-4-Hierarchical-Softmax"><a href="#2-4-Hierarchical-Softmax" class="headerlink" title="2.4 Hierarchical Softmax"></a>2.4 Hierarchical Softmax</h2><p>分层softmax（Hierarchical Softmax）本质是优化版softmax，<strong>即引入Hierarchical Softmax仅是代替原来softmax结构，优化output vector计算复杂度</strong>。</p>
<ul>
<li>原softmax：$y_{i}=\frac{exp(x_i)}{\sum_{a=1}^{V}{exp(x_a)}}$，其中$x_i$为输入向量$X_{V×1}$第$i$位数值标量，$y_i$则为对应输出，输出向量$Y_{V×1}$</li>
</ul>
<p>可以看出，计算一次$y_i$需要知道所有$x_{i}$值。复杂度为O(V)。</p>
<ul>
<li><p>Hierarchical Softmax：引入霍夫曼树，首先依据词频构建霍夫曼树，词语节点都是叶节点。q</p>
<p>如下图为论文原图</p>
<p><img src="https://raw.githubusercontent.com/Eajack/NLP-Papers/master/Word%20Embedding%E8%AF%8D%E5%90%91%E9%87%8F/Word2vec/%E5%9B%BE4.PNG" alt="图4- Hierarchical Softmax"></p>
</li>
</ul>
<p>在Hierarchical Softmax中，举例如上图，计算词语$w_{2}$对应的softmax近似概率（H-softmax计算近似值）：</p>
<script type="math/tex; mode=display">
y_{i}=P(w_{2}=w_{O})=P(n(w_2,1),left)*P(n(w_2,2),left)*P(n(w_2,3),right)=σ(v^{'T}_{n(w_{2},1)}h)*σ(v^{'T}_{n(w_{2},2)}h)*(1-σ(v^{'T}_{n(w_{2},3)}h))</script><p>其中$v^{‘T}_{n(w_{2},1)}、v^{‘T}_{n(w_{2},2)}、v^{‘T}_{n(w_{2},3)}$分别为3个节点参数，需要训练更新。</p>
<p>且</p>
<script type="math/tex; mode=display">
\sum_{a=1}^{V}{P(w_{i}=w_{O})}=1</script><p>为表示方便，上图例子公式如下</p>
<script type="math/tex; mode=display">
y_{i}=σ(θ^{'T}_{n(w_{2},1)}h)*σ(θ^{'T}_{n(w_{2},2)}h)*(1-σ(θ^{'T}_{n(w_{2},3)}h))</script><p>其中，$σ(x)$函数为二元逻辑回归函数$y=\frac{1}{1+exp(-X^{T}*θ)}$。</p>
<p>容易看出，上面计算$y_{i}$公式计算复杂度下降，不再需要计算V步，仅需要$log(V)$步（即$w_2$路径长）。所以Hierarchical Softmax的计算复杂度为$O(log(V))$</p>
<p><strong>参数更新：</strong></p>
<script type="math/tex; mode=display">
\theta^{(new)}_j = \theta^{(old)}_j – \eta(\sigma({\theta_j}^Th)-t_j)h</script><h2 id="2-5-Negative-Sampling"><a href="#2-5-Negative-Sampling" class="headerlink" title="2.5 Negative Sampling"></a>2.5 Negative Sampling</h2><p>参考博客文章<a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a>，总结如下。</p>
<p><strong>Negative Sampling，是代替H-softmax方法的另一种优化计算output vector的方法。</strong>如其名，这方法涉及采样（Sampling）。</p>
<ul>
<li><p>大致原理：现有训练样本,包括当前中心词$w$和C个上下文词$Context(w)$（上下文分别$\frac{2}{C}$个词），命名为<strong>正例</strong>。对词库进行负采样（Negative Sampling），得到<strong>非$w$的N个中心词$w_i(i=1,2,···,N)$</strong>，将N个样本$w_i、Context(w)(i=1,2,···,N)$（注意：$Context(w)$没变，只是中心词w变了）一起作为训练样本，命名为<strong>负例</strong>。正例 &amp; 负例 =&gt; loss function。</p>
</li>
<li><p>2个问题：如上原理介绍，有2个问题：</p>
<ul>
<li>Q1：如何Negative Sampling获得<strong>非$w$的N个中心词$w_i(i=1,2,···,N)$</strong>？</li>
<li>Q2：如何根据正负样例构造loss function？</li>
</ul>
</li>
<li><p>Q1：Negative Sampling</p>
<p>词库词语数量为V，引入长度为1的标准线L，将其分为V份，每一小段对应1个词语。Word2vec中，定义每个词语对应的长度为$len(w_{i})=\frac{count(w_{i})^{3/4}}{\sum_{a=1}^{V}{count(w_{i})^{3/4}}}$，且有$\sum_{a=1}^{V}{len(w_i)=1}$。</p>
<p>采样前，将标准线L等分为M份（M&gt;&gt;V，Word2vec中M取$10^{8}$），因此每个词长可以对应若干个M小份长度。如下图为博客图片：</p>
<p><img src="https://raw.githubusercontent.com/Eajack/NLP-Papers/master/Word%20Embedding%E8%AF%8D%E5%90%91%E9%87%8F/Word2vec/%E5%9B%BE5.PNG" alt="图5- Negative Sampling"></p>
<p>采样时，随机在M个位置中采样N个$m_{i}$位置，则每一个位置肯定落入对应的1个词语。注意：采样词不要重复且不能和当前中心词$w$一样。</p>
</li>
<li><p>Q2：loss function</p>
<p>定义当前词$w$为$w_{0}$，正例为$[w_{0},Context(w_{0})]$,负例为$[w_{i},Context(w_{i})]（i=1,2,···,N）$。</p>
<p>根据逻辑函数有正例概率：</p>
<script type="math/tex; mode=display">
P(context(w_0), w_i) = \sigma(x_{w_0}^T\theta^{w_i}) ,y_i=1, i=0</script><p>负例概率：</p>
<script type="math/tex; mode=display">
P(context(w_0), w_i) =1-  \sigma(x_{w_0}^T\theta^{w_i}), y_i = 0, i=1,2,..N</script><p>最大化公式：</p>
<script type="math/tex; mode=display">
\prod_{i=0}^{N}P(context(w_0), w_i) = \sigma(x_{w_0}^T\theta^{w_0})\prod_{i=1}^{N}(1-  \sigma(x_{w_0}^T\theta^{w_i}))</script><p>似然函数：</p>
<script type="math/tex; mode=display">
Q=\prod_{i=0}^{N} \sigma(x_{w_0}^T\theta^{w_i})^{y_i}(1-  \sigma(x_{w_0}^T\theta^{w_i}))^{1-y_i}</script><p>log似然：</p>
<script type="math/tex; mode=display">
L = \sum\limits_{i=0}^{N}y_i log(\sigma(x_{w_0}^T\theta^{w_i})) + (1-y_i) log(1-  \sigma(x_{w_0}^T\theta^{w_i}))</script><p><strong>参数更新：（SGD算法）</strong></p>
<p>类似前面操作，最终有参数$x_{w_0}, \theta^{w_i},  i=0,1,..N$更新公式。具体参考<a href="https://www.cnblogs.com/pinard/p/7249903.html" target="_blank" rel="noopener">word2vec原理(三) 基于Negative Sampling的模型</a>。</p>
</li>
</ul>
<h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><ul>
<li><p><strong>Word2vec = CBOW + Skip-Gram（Hierarchical Softmax &amp; Negative Sampling）</strong></p>
<p>其中，CBOW：上下文词语 预测 中心词；Skip-Gram：中心词 预测 上下文词语</p>
</li>
<li><p><strong>Word2vec词向量仅是模型副产品，即输入向量矩阵W</strong></p>
</li>
</ul>

    

    
</div>


                

                <!-- Post Comments -->
                
                    
                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2019/06/21/blog建站日志/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2019/06/12/Eajack LeetCode Notes- Day3/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>


                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/sidebar_header.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/img/avatar.jpg" alt="Eajack Lau's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        eajacklau@163.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="mailto:eajacklau@163.com" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    归档
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2019/08/">八月 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/07/">七月 2019<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/06/">六月 2019<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/05/">五月 2019<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/02/">二月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/01/">一月 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/02/">二月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/08/">八月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/07/">七月 2017<span class="sidebar_archives-count">2</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                分类
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                <a class="sidebar_archives-link" href="/categories/C/">C++<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/GitHub/">GitHub<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/LeetCode/">LeetCode<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/categories/Markdown/">Markdown<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/NLP/">NLP<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/categories/OpenCV/">OpenCV<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/">Python<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/Songs/">Songs<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/blog/">blog<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/心情/">心情<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/数学建模/">数学建模<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/数据结构-算法/">数据结构&算法<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/机器学习/">机器学习<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/杂乱/">杂乱<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/树莓派/">树莓派<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/爬虫/">爬虫<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/鸡汤/">鸡汤<span class="sidebar_archives-count">3</span></a>
            </ul>
        </li>
        
    

    <!-- Pages  -->
    
        <li>
            <a href="/tags" title="标签云">
                
                    <i class="material-icons sidebar-material-icons">cloud_circle</i>
                
                标签云
            </a>
        </li>
        
            <li class="divider"></li>
        
    
        <li>
            <a href="/timeline" title="Timeline">
                
                    <i class="material-icons sidebar-material-icons">send</i>
                
                Timeline
            </a>
        </li>
        
    
        <li>
            <a href="/aboutMe" title="About Me">
                
                    <i class="material-icons sidebar-material-icons">person_pin</i>
                
                About Me
            </a>
        </li>
        
    
        <li>
            <a href="/_aboutMe" title="关于我">
                
                    <i class="material-icons sidebar-material-icons">person_pin</i>
                
                关于我
            </a>
        </li>
        
            <li class="divider"></li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                文章总数
                <span class="sidebar-badge">38</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->


<!-- Theme Material -->


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/Eajack" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    
        <a href="https://www.zhihu.com/people/Eajack_Lau-CGH-LEO/activities" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-zhihu">
                <span class="visuallyhidden">Zhihu</span>
            </button><!--
     --></a>
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>Eajack's Blog
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import File -->


    <script>lsloader.load("js/lazyload.min.js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==")</script>
    <script>lsloader.load("js/js.min.js","/js/js.min.js?oAl/+lvaqTFV31JXTmbrNA==")</script>



    <script>lsloader.load("js/nprogress.js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==")</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>







    <!-- Busuanzi -->
    <script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>







<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Window Load-->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });
</script>

<!-- MathJax Load-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

    <script type="text/javascript" src="/js/mathjax.js?config=TeX-AMS-MML_HTMLorMML"></script>



<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Bing Background -->


<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.4.0 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>
</body>
    
</html>
